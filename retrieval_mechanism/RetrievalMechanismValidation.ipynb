{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce8844f-5bcf-4d4f-b552-802784631c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.encoder import QCLR_Classifier, COMET_Classifier\n",
    "from tasks.fine_tuning import finetune_predict\n",
    "from config_files.ASAN_Configs import Config as Configs\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import sklearn\n",
    "from utils import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "from dtaidistance import dtw\n",
    "import pingouin as pg\n",
    "from scipy.stats import iqr as scipy_iqr\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ef8863-9240-4164-b251-257c5515f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program will run on cuda!\n",
      "\n",
      "--- Processing Fold 1 ---\n",
      "Fold 1:\n",
      "Train set size: 9500 6405 3095\n",
      "Train set size: 2374 1595 779\n",
      "Train set size: 2969 2000 969\n",
      "Number of Selected Patient (critical intervention):  (1149,)\n",
      "eSOFA Score (unique):  [0.         0.00199203 0.20119522 0.40039841 0.59960159 0.79880478\n",
      " 0.99800797]\n",
      "Calculating average feature vectors for FeatureAvg baseline...\n",
      "Average feature vectors calculated.\n",
      "Calculating Top-3 similar patients and SOFA DTW distances...\n",
      "Calculation finished.\n",
      "Number of valid paired comparisons: 1149\n",
      "\n",
      "--- Processing Fold 2 ---\n",
      "Fold 2:\n",
      "Train set size: 9500 6391 3109\n",
      "Train set size: 2374 1609 765\n",
      "Train set size: 2969 2000 969\n",
      "Number of Selected Patient (critical intervention):  (1135,)\n",
      "eSOFA Score (unique):  [0.         0.00199203 0.20119522 0.40039841 0.59960159 0.79880478\n",
      " 0.99800797]\n",
      "Calculating average feature vectors for FeatureAvg baseline...\n",
      "Average feature vectors calculated.\n",
      "Calculating Top-3 similar patients and SOFA DTW distances...\n",
      "Calculation finished.\n",
      "Number of valid paired comparisons: 1135\n",
      "\n",
      "--- Processing Fold 3 ---\n",
      "Fold 3:\n",
      "Train set size: 9500 6388 3112\n",
      "Train set size: 2374 1612 762\n",
      "Train set size: 2969 2000 969\n",
      "Number of Selected Patient (critical intervention):  (1139,)\n",
      "eSOFA Score (unique):  [0.         0.00199203 0.20119522 0.40039841 0.59960159 0.79880478\n",
      " 0.99800797]\n",
      "Calculating average feature vectors for FeatureAvg baseline...\n",
      "Average feature vectors calculated.\n",
      "Calculating Top-3 similar patients and SOFA DTW distances...\n",
      "Calculation finished.\n",
      "Number of valid paired comparisons: 1139\n",
      "\n",
      "--- Processing Fold 4 ---\n",
      "Fold 4:\n",
      "Train set size: 9500 6377 3123\n",
      "Train set size: 2375 1623 752\n",
      "Train set size: 2968 2000 968\n",
      "Number of Selected Patient (critical intervention):  (1157,)\n",
      "eSOFA Score (unique):  [0.         0.00199203 0.20119522 0.40039841 0.59960159 0.79880478\n",
      " 0.99800797]\n",
      "Calculating average feature vectors for FeatureAvg baseline...\n",
      "Average feature vectors calculated.\n",
      "Calculating Top-3 similar patients and SOFA DTW distances...\n",
      "Calculation finished.\n",
      "Number of valid paired comparisons: 1157\n",
      "\n",
      "--- Processing Fold 5 ---\n",
      "Fold 5:\n",
      "Train set size: 9500 6374 3126\n",
      "Train set size: 2375 1626 749\n",
      "Train set size: 2968 2000 968\n",
      "Number of Selected Patient (critical intervention):  (1096,)\n",
      "eSOFA Score (unique):  [0.         0.00199203 0.20119522 0.40039841 0.59960159 0.79880478\n",
      " 0.99800797]\n",
      "Calculating average feature vectors for FeatureAvg baseline...\n",
      "Average feature vectors calculated.\n",
      "Calculating Top-3 similar patients and SOFA DTW distances...\n",
      "Calculation finished.\n",
      "Number of valid paired comparisons: 1096\n",
      "\n",
      "--- Summary Statistics (eSOFA Score) ---\n",
      "    Method  Mean DTW  Std Dev DTW  Median DTW  IQR DTW  N Valid\n",
      "  My Model    0.4249       0.2689      0.3716   0.2834     5676\n",
      "Base Model    0.4498       0.2730      0.3984   0.3058     5676\n",
      "    Random    0.8635       0.4665      0.7641   0.5797     5676\n",
      "FeatureAvg    0.6424       0.4287      0.5390   0.5033     5676\n",
      "\n",
      "--- Summary Statistics (Total Bilirubin) ---\n",
      "    Method  Mean DTW  Std Dev DTW  Median DTW  IQR DTW  N Valid\n",
      "  My Model    1.1408       0.4562      1.1811   0.6064     5676\n",
      "Base Model    1.2209       0.4885      1.2552   0.6468     5676\n",
      "    Random    1.2526       0.5689      1.2464   0.7218     5676\n",
      "FeatureAvg    1.5427       0.7153      1.4847   0.8751     5676\n",
      "\n",
      "--- Summary Statistics (Platelet Count) ---\n",
      "    Method  Mean DTW  Std Dev DTW  Median DTW  IQR DTW  N Valid\n",
      "  My Model    0.6090       0.2948      0.5654   0.3860     5676\n",
      "Base Model    0.6548       0.3240      0.6079   0.4101     5676\n",
      "    Random    0.6717       0.4484      0.5849   0.5603     5676\n",
      "FeatureAvg    0.8094       0.4518      0.6985   0.5313     5676\n",
      "\n",
      "--- Summary Statistics (Lactic Acid) ---\n",
      "    Method  Mean DTW  Std Dev DTW  Median DTW  IQR DTW  N Valid\n",
      "  My Model    0.7846       0.3502      0.7668   0.4792     5676\n",
      "Base Model    0.8478       0.3863      0.8251   0.5194     5676\n",
      "    Random    0.8740       0.4928      0.8131   0.6313     5676\n",
      "FeatureAvg    1.0343       0.5432      0.9443   0.6689     5676\n",
      "\n",
      "--- Statistical Test (Wilcoxon Signed-Rank Test) ---\n",
      "\n",
      "--- Statistical Tests (eSOFA Score) ---\n",
      "\n",
      "Comparison: My Model vs Base Model\n",
      "   Wilcoxon Test (H1: My Model < Base Model):\n",
      "     P-value: 3.103e-19\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.1409\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5314\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs Random\n",
      "   Wilcoxon Test (H1: My Model < Random):\n",
      "     P-value: 0\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.8799\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.8206\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs FeatureAvg\n",
      "   Wilcoxon Test (H1: My Model < FeatureAvg):\n",
      "     P-value: 0\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.6428\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.6627\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "--- Statistical Tests (Total Bilirubin) ---\n",
      "\n",
      "Comparison: My Model vs Base Model\n",
      "   Wilcoxon Test (H1: My Model < Base Model):\n",
      "     P-value: 1.022e-130\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.3764\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5510\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs Random\n",
      "   Wilcoxon Test (H1: My Model < Random):\n",
      "     P-value: 3.496e-94\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.3151\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5556\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs FeatureAvg\n",
      "   Wilcoxon Test (H1: My Model < FeatureAvg):\n",
      "     P-value: 0\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.7723\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.6749\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "--- Statistical Tests (Platelet Count) ---\n",
      "\n",
      "Comparison: My Model vs Base Model\n",
      "   Wilcoxon Test (H1: My Model < Base Model):\n",
      "     P-value: 3.447e-33\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.1850\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5394\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs Random\n",
      "   Wilcoxon Test (H1: My Model < Random):\n",
      "     P-value: 1.259e-12\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.1073\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5105\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs FeatureAvg\n",
      "   Wilcoxon Test (H1: My Model < FeatureAvg):\n",
      "     P-value: 5.346e-230\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.4961\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.6334\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "--- Statistical Tests (Lactic Acid) ---\n",
      "\n",
      "Comparison: My Model vs Base Model\n",
      "   Wilcoxon Test (H1: My Model < Base Model):\n",
      "     P-value: 8.522e-54\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.2386\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5460\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs Random\n",
      "   Wilcoxon Test (H1: My Model < Random):\n",
      "     P-value: 2.219e-37\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.1950\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.5429\n",
      "     Result: Statistically significant difference (p < 0.05).\n",
      "\n",
      "Comparison: My Model vs FeatureAvg\n",
      "   Wilcoxon Test (H1: My Model < FeatureAvg):\n",
      "     P-value: 2.777e-301\n",
      "     Effect Size (Rank-Biserial Correlation, RBC): -0.5692\n",
      "     Effect Size (Common Language Effect Size, CLES): 0.6339\n",
      "     Result: Statistically significant difference (p < 0.05).\n"
     ]
    }
   ],
   "source": [
    "configs = Configs()\n",
    "RANDOM_SEED = configs.RANDOM_SEED\n",
    "seed_everything(RANDOM_SEED)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Suppress simple warnings\n",
    "\n",
    "working_directory = configs.working_directory\n",
    "dataset_save_path = working_directory\n",
    "if not os.path.exists(working_directory):\n",
    "    os.makedirs(working_directory)\n",
    "logging_directory = configs.logging_directory\n",
    "if not os.path.exists(logging_directory):\n",
    "    os.makedirs(logging_directory)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set the GPU 0 to use\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The program will run on {device}!\")\n",
    "\n",
    "# --- Loop through each fold ---\n",
    "N_FOLDS = 5\n",
    "# SOFA Score: Initialize lists to store results across all folds (Model: QCLR, COMET, RANDOM, FeatureAVG)\n",
    "all_folds_my_dtw = []\n",
    "all_folds_base_dtw = []\n",
    "all_folds_random_dtw = []\n",
    "all_folds_featavg_dtw = []\n",
    "# Total Bilirubin: Initialize lists to store results across all folds (Model: QCLR, COMET, RANDOM, FeatureAVG)\n",
    "all_folds_my_tbil_dtw = []\n",
    "all_folds_base_tbil_dtw = []\n",
    "all_folds_random_tbil_dtw = []\n",
    "all_folds_featavg_tbil_dtw = []\n",
    "# Platelet Count: Initialize lists to store results across all folds (Model: QCLR, COMET, RANDOM, FeatureAVG)\n",
    "all_folds_my_plt_dtw = []\n",
    "all_folds_base_plt_dtw = []\n",
    "all_folds_random_plt_dtw = []\n",
    "all_folds_featavg_plt_dtw = []\n",
    "# Lactic Acid: Initialize lists to store results across all folds (Model: QCLR, COMET, RANDOM, FeatureAVG)\n",
    "all_folds_my_latic_dtw = []\n",
    "all_folds_base_latic_dtw = []\n",
    "all_folds_random_latic_dtw = []\n",
    "all_folds_featavg_latic_dtw = []\n",
    "\n",
    "for i in range(1, N_FOLDS + 1):\n",
    "    print(f\"\\n--- Processing Fold {i} ---\")\n",
    "\n",
    "    # --- A. Load Data and Embeddings for the fold ---\n",
    "    with open('data/asan_fold_' + str(i) + '.pkl', 'rb') as f:\n",
    "        fold_data = pickle.load(f)\n",
    "\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(\"Train set size:\", len(fold_data['X_train']),\n",
    "          (fold_data['y_train'] == 0).sum(), (fold_data['y_train'] == 1).sum())\n",
    "    print(\"Train set size:\", len(fold_data['X_val']),\n",
    "          (fold_data['y_val'] == 0).sum(), (fold_data['y_val'] == 1).sum())\n",
    "    print(\"Train set size:\", len(fold_data['X_test']),\n",
    "          (fold_data['y_test'] == 0).sum(), (fold_data['y_test'] == 1).sum())\n",
    "\n",
    "    X_train = fold_data['X_train']\n",
    "    X_val = fold_data['X_val']\n",
    "    X_test = fold_data['X_test']\n",
    "\n",
    "    y_train = fold_data['y_train']\n",
    "    y_val = fold_data['y_val']\n",
    "    y_test = fold_data['y_test']\n",
    "\n",
    "    seq_train = fold_data['seq_train']\n",
    "    seq_val = fold_data['seq_valid']\n",
    "    seq_test = fold_data['seq_test']\n",
    "\n",
    "    id_train = fold_data['id_train']\n",
    "    id_val = fold_data['id_valid']\n",
    "    id_test = fold_data['id_test']\n",
    "\n",
    "    X_val = X_train.copy()\n",
    "    seq_val = seq_train.copy()\n",
    "    y_val = y_train.copy()\n",
    "    id_val = id_train.copy()\n",
    "\n",
    "    target_features = [59, 60, 70] # critical intervention (59-intubation, 60-ECMO, 70-surgery)\n",
    "    mask = np.any(np.any(X_test[:, :, target_features] == 1, axis=1), axis=1)\n",
    "    indices = np.where(mask)[0]\n",
    "    print('Number of Selected Patient (critical intervention): ', indices.shape)\n",
    "    X_test = X_test[indices]\n",
    "    y_test = y_test[indices]\n",
    "    seq_test = seq_test[indices]\n",
    "    id_test = id_test[indices]\n",
    "\n",
    "    X_test_ori = X_test.copy()\n",
    "    '''\n",
    "    clinical decision support is often critical during the initial stages of treatment planning, \n",
    "    we utilized only the early phase, specifically the first four time steps, of these high-risk test patient time series for evaluating similarity. \n",
    "    '''\n",
    "    X_test[:, 4:, :] = 0\n",
    "    seq_test[:] = 3\n",
    "\n",
    "    model = QCLR_Classifier(input_dims=configs.input_dims,\n",
    "                          output_dims=configs.output_dims,\n",
    "                          depth=configs.depth,\n",
    "                          p_output_dims=configs.num_classes, device=device,\n",
    "                          flag_use_multi_gpu=configs.flag_use_multi_gpu)\n",
    "\n",
    "    RANDOM_SEED = i\n",
    "    model.load_state_dict(torch.load(\"test_run/models/QCLR_ASAN/seed\" + str(RANDOM_SEED) + \".pt\"))\n",
    "    model.eval()\n",
    "    _, emb_val_tensor = finetune_predict(model, X_val, y_val)\n",
    "    _, emb_test_tensor = finetune_predict(model, X_test, y_test)\n",
    "    print('eSOFA Score (unique): ', np.unique(X_val[:, :, 56]))\n",
    "    del model \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = COMET_Classifier(input_dims=configs.input_dims,\n",
    "                         output_dims=configs.output_dims,\n",
    "                         depth=configs.depth,\n",
    "                         p_output_dims=configs.num_classes, device=device,\n",
    "                         flag_use_multi_gpu=configs.flag_use_multi_gpu)\n",
    "    model.load_state_dict(torch.load(\n",
    "        \"test_run/models/COMET_ASAN/seed\" + str(RANDOM_SEED) + \".pt\"))\n",
    "    model.eval()\n",
    "    _, emb_val_base_tensor = finetune_predict(model, X_val, y_val)\n",
    "    _, emb_test_base_tensor = finetune_predict(model, X_test, y_test)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert embeddings to numpy and normalize\n",
    "    my_emd_train = emb_val_tensor.cpu().numpy()\n",
    "    my_emd_test = emb_test_tensor.cpu().numpy()\n",
    "    base_emd_train = emb_val_base_tensor.cpu().numpy()\n",
    "    base_emd_test = emb_test_base_tensor.cpu().numpy()\n",
    "\n",
    "    K = 3  # Top-K similiar patients\n",
    "    ''' Selecting sepsis-related blood test indicators (SOFA score, Total Bilirubin, Platelet Count, Lactic Acid) '''\n",
    "    SOFA_FEATURE_INDEX = 56  # SOFA score (Index 56)\n",
    "    TBIL_FEATURE_INDEX = 27  # Total Bilirubin\n",
    "    PLT_FEATURE_INDEX = 36  # Platelet Count\n",
    "    LATIC_FEATURE_INDEX = 49  # Lactic Acid\n",
    "    n_train_patients = X_val.shape[0]\n",
    "    n_test_patients = X_test.shape[0]\n",
    "    max_seq_len = X_val.shape[1]\n",
    "    n_features = X_val.shape[2]\n",
    "    my_embedding_dim = 128\n",
    "    base_embedding_dim = 320\n",
    "\n",
    "    def get_sequence(patient_data, seq_length, feature_index):\n",
    "        \"\"\"\n",
    "        Extract a time series of SOFA scores from given patient data and actual sequence lengths.\n",
    "        \"\"\"\n",
    "        if seq_length <= 0:\n",
    "            return None\n",
    "        sofa_score = patient_data[:seq_length+1, feature_index]\n",
    "        return sofa_score\n",
    "\n",
    "    print(\"Calculating average feature vectors for FeatureAvg baseline...\")\n",
    "    avg_vec_train = np.zeros((n_train_patients, n_features))\n",
    "    for j in range(n_train_patients):\n",
    "        s_len = seq_val[j].astype(int)+1\n",
    "        if s_len > 0:\n",
    "            avg_vec_train[j, :] = np.mean(X_val[j, :s_len, :], axis=0)\n",
    "\n",
    "    avg_vec_test = np.zeros((n_test_patients, n_features))\n",
    "    for i in range(n_test_patients):\n",
    "        s_len = seq_test[i].astype(int)+1\n",
    "        if s_len > 0:\n",
    "            avg_vec_test[i, :] = np.mean(X_test[i, :s_len, :], axis=0)\n",
    "    print(\"Average feature vectors calculated.\")\n",
    "\n",
    "    # --- Steps 1 & 2: Find similar patients and calculate SOFA DTW distance ---\n",
    "    my_model_avg_dtw_distances = []\n",
    "    base_model_avg_dtw_distances = []\n",
    "    random_model_avg_dtw_distances = []\n",
    "    featavg_model_avg_dtw_distances = []\n",
    "\n",
    "    my_model_avg_dtw_tbil_distances = []\n",
    "    base_model_avg_dtw_tbil_distances = []\n",
    "    random_model_avg_dtw_tbil_distances = []\n",
    "    featavg_model_avg_dtw_tbil_distances = []\n",
    "\n",
    "    my_model_avg_dtw_plt_distances = []\n",
    "    base_model_avg_dtw_plt_distances = []\n",
    "    random_model_avg_dtw_plt_distances = []\n",
    "    featavg_model_avg_dtw_plt_distances = []\n",
    "\n",
    "    my_model_avg_dtw_latic_distances = []\n",
    "    base_model_avg_dtw_latic_distances = []\n",
    "    random_model_avg_dtw_latic_distances = []\n",
    "    featavg_model_avg_dtw_latic_distances = []\n",
    "\n",
    "    #  Repeat with each patient in the test set as a 'reference patient (anchor)'\n",
    "    print(f\"Calculating Top-{K} similar patients and SOFA DTW distances...\")\n",
    "    for ref_idx in range(n_test_patients): \n",
    "\n",
    "        # 0. Extract the actual SOFA/ time series for the baseline patient\n",
    "        ref_sofa_seq = get_sequence(X_test[ref_idx], seq_test[ref_idx].astype(int), SOFA_FEATURE_INDEX)\n",
    "        ref_tbil_seq = get_sequence(X_test[ref_idx], seq_test[ref_idx].astype(int), TBIL_FEATURE_INDEX)\n",
    "        ref_plt_seq = get_sequence(X_test[ref_idx], seq_test[ref_idx].astype(int), PLT_FEATURE_INDEX)\n",
    "        ref_latic_seq = get_sequence(X_test[ref_idx], seq_test[ref_idx].astype(int), LATIC_FEATURE_INDEX)\n",
    "\n",
    "        if ref_sofa_seq is None or len(ref_sofa_seq) == 0:\n",
    "            # print(f\"Skipping reference patient {ref_idx} due to zero or invalid sequence length.\")\n",
    "            continue  # Skip if there is no SOFA time series for similar patients\n",
    "\n",
    "        # --- Our Model (QCLR) ---\n",
    "        # 1. Calculate cosine similarity (reference patient vs all test patients)\n",
    "        similarities_my = cosine_similarity(my_emd_test[ref_idx].reshape(1, -1), my_emd_train)[0]\n",
    "\n",
    "        # Sort indices by highest similarity and select top K\n",
    "        top_k_indices_my = np.argsort(similarities_my)[::-1][:K]\n",
    "        # top_k_indices_my = np.argsort(similarities_my)[:K]\n",
    "\n",
    "        # 2.  Calculate SOFA DTW distance between Top K similar patients and reference patients\n",
    "        dtw_distances_my = []\n",
    "        dtw_distances_tbil_my = []\n",
    "        dtw_distances_plt_my = []\n",
    "        dtw_distances_latic_my = []\n",
    "        dtw_treatment_my = 0\n",
    "        for sim_idx in top_k_indices_my:\n",
    "            sim_sofa_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), SOFA_FEATURE_INDEX)\n",
    "            sim_tbil_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), TBIL_FEATURE_INDEX)\n",
    "            sim_plt_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), PLT_FEATURE_INDEX)\n",
    "            sim_latic_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), LATIC_FEATURE_INDEX)\n",
    "            if sim_sofa_seq is None or len(sim_sofa_seq) == 0:\n",
    "                # print(f\"  Skipping similar patient {sim_idx} (my model) for ref {ref_idx} due to zero length.\")\n",
    "                continue  # Skip if there is no SOFA time series for similar patients\n",
    "\n",
    "            # DTW distance\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_sofa_seq)\n",
    "            dtw_distances_my.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_tbil_seq)\n",
    "            dtw_distances_tbil_my.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_plt_seq)\n",
    "            dtw_distances_plt_my.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_latic_seq)\n",
    "            dtw_distances_latic_my.append(distance)\n",
    "\n",
    "            sim_samples = X_val[sim_idx]\n",
    "            if np.any(sim_samples[:, target_features] == 1):\n",
    "                dtw_treatment_my += 1\n",
    "\n",
    "        # Get Avg. DTW distances\n",
    "        if len(dtw_distances_my) > 0:\n",
    "            avg_dtw_my = np.mean(dtw_distances_my)\n",
    "            avg_dtw_tbil_my = np.mean(dtw_distances_tbil_my)\n",
    "            avg_dtw_plt_my = np.mean(dtw_distances_plt_my)\n",
    "            avg_dtw_latic_my = np.mean(dtw_distances_latic_my)\n",
    "        else:\n",
    "            avg_dtw_my = np.nan  # if cannot calculate, NaN\n",
    "\n",
    "        # --- Baselines (COMET, Random, FeatAvg) ---\n",
    "        # Cosine similarity\n",
    "        similarities_base = cosine_similarity(base_emd_test[ref_idx].reshape(1, -1), base_emd_train)[0]\n",
    "\n",
    "        # Find Top-K\n",
    "        top_k_indices_base = np.argsort(similarities_base)[::-1][:K]\n",
    "\n",
    "        # 2. COMET (baseline #1)\n",
    "        dtw_distances_base = []\n",
    "        dtw_distances_tbil_base = []\n",
    "        dtw_distances_plt_base = []\n",
    "        dtw_distances_latic_base = []\n",
    "        dtw_treatment_base = 0\n",
    "        for sim_idx in top_k_indices_base:\n",
    "            sim_sofa_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), SOFA_FEATURE_INDEX)\n",
    "            sim_tbil_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), TBIL_FEATURE_INDEX)\n",
    "            sim_plt_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), PLT_FEATURE_INDEX)\n",
    "            sim_latic_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), LATIC_FEATURE_INDEX)\n",
    "            if sim_sofa_seq is None or len(sim_sofa_seq) == 0:\n",
    "                # print(f\"  Skipping similar patient {sim_idx} (base model) for ref {ref_idx} due to zero length.\")\n",
    "                continue\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_sofa_seq)\n",
    "            dtw_distances_base.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_tbil_seq)\n",
    "            dtw_distances_tbil_base.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_plt_seq)\n",
    "            dtw_distances_plt_base.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_latic_seq)\n",
    "            dtw_distances_latic_base.append(distance)\n",
    "\n",
    "            sim_samples = X_val[sim_idx]\n",
    "            if np.any(sim_samples[:, target_features] == 1):\n",
    "                dtw_treatment_base += 1\n",
    "\n",
    "        # Avg. DTW \n",
    "        if len(dtw_distances_base) > 0:\n",
    "            avg_dtw_base = np.mean(dtw_distances_base)\n",
    "            avg_dtw_tbil_base = np.mean(dtw_distances_tbil_base)\n",
    "            avg_dtw_plt_base = np.mean(dtw_distances_plt_base)\n",
    "            avg_dtw_latic_base = np.mean(dtw_distances_latic_base)\n",
    "        else:\n",
    "            avg_dtw_base = np.nan\n",
    "\n",
    "        # 3. Random (baseline #2)\n",
    "        possible_indices = list(range(n_train_patients))\n",
    "        k_random = min(K, n_train_patients)\n",
    "        random_k_indices = np.random.choice(possible_indices, k_random,\n",
    "                                            replace=False)\n",
    "        dtw_distances_random = []\n",
    "        dtw_distances_tbil_random = []\n",
    "        dtw_distances_plt_random = []\n",
    "        dtw_distances_latic_random = []\n",
    "        dtw_treatment_random = 0\n",
    "        for rand_idx in random_k_indices:\n",
    "            rand_sofa_seq = get_sequence(X_val[rand_idx], seq_val[rand_idx].astype(int), SOFA_FEATURE_INDEX)\n",
    "            sim_tbil_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), TBIL_FEATURE_INDEX)\n",
    "            sim_plt_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), PLT_FEATURE_INDEX)\n",
    "            sim_latic_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), LATIC_FEATURE_INDEX)\n",
    "            if rand_sofa_seq is None or len(rand_sofa_seq) == 0: continue\n",
    "            distance = dtw.distance(ref_sofa_seq, rand_sofa_seq)\n",
    "            dtw_distances_random.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_tbil_seq)\n",
    "            dtw_distances_tbil_random.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_plt_seq)\n",
    "            dtw_distances_plt_random.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_latic_seq)\n",
    "            dtw_distances_latic_random.append(distance)\n",
    "\n",
    "            sim_samples = X_val[sim_idx]\n",
    "            if np.any(sim_samples[:, target_features] == 1):\n",
    "                dtw_treatment_random += 1\n",
    "\n",
    "        if len(dtw_distances_random) > 0:\n",
    "            avg_dtw_random = np.mean(dtw_distances_random)\n",
    "            avg_dtw_tbil_random = np.mean(dtw_distances_tbil_random)\n",
    "            avg_dtw_plt_random = np.mean(dtw_distances_plt_random)\n",
    "            avg_dtw_latic_random = np.mean(dtw_distances_latic_random)\n",
    "        else:\n",
    "            avg_dtw_random = np.nan\n",
    "\n",
    "        # 4. FeatureAvg (baseline #3)\n",
    "        similarities_featavg = cosine_similarity(avg_vec_test[ref_idx].reshape(1, -1), avg_vec_train)[0]\n",
    "        top_k_indices_featavg = np.argsort(similarities_featavg)[::-1][:K]\n",
    "        dtw_distances_featavg = []\n",
    "        dtw_distances_tbil_featavg = []\n",
    "        dtw_distances_plt_featavg = []\n",
    "        dtw_distances_latic_featavg = []\n",
    "        dtw_treatment_featavg = 0\n",
    "        for sim_idx in top_k_indices_featavg:\n",
    "            sim_sofa_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), SOFA_FEATURE_INDEX)\n",
    "            sim_tbil_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), TBIL_FEATURE_INDEX)\n",
    "            sim_plt_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), PLT_FEATURE_INDEX)\n",
    "            sim_latic_seq = get_sequence(X_val[sim_idx], seq_val[sim_idx].astype(int), LATIC_FEATURE_INDEX)\n",
    "            if sim_sofa_seq is None or len(sim_sofa_seq) == 0: continue\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_sofa_seq)\n",
    "            dtw_distances_featavg.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_tbil_seq)\n",
    "            dtw_distances_tbil_featavg.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_plt_seq)\n",
    "            dtw_distances_plt_featavg.append(distance)\n",
    "\n",
    "            distance = dtw.distance(ref_sofa_seq, sim_latic_seq)\n",
    "            dtw_distances_latic_featavg.append(distance)\n",
    "\n",
    "            sim_samples = X_val[sim_idx]\n",
    "            if np.any(sim_samples[:, target_features] == 1):\n",
    "                dtw_treatment_featavg += 1\n",
    "\n",
    "        if len(dtw_distances_featavg) > 0:\n",
    "            avg_dtw_featavg = np.mean(dtw_distances_featavg)\n",
    "            avg_dtw_tbil_featavg = np.mean(dtw_distances_tbil_featavg)\n",
    "            avg_dtw_plt_featavg = np.mean(dtw_distances_plt_featavg)\n",
    "            avg_dtw_latic_featavg = np.mean(dtw_distances_latic_featavg)\n",
    "        else:\n",
    "            avg_dtw_featavg = np.nan\n",
    "\n",
    "        # Saving Results (except NaN)\n",
    "        my_model_avg_dtw_distances.append(avg_dtw_my)\n",
    "        base_model_avg_dtw_distances.append(avg_dtw_base)\n",
    "        random_model_avg_dtw_distances.append(avg_dtw_random)\n",
    "        featavg_model_avg_dtw_distances.append(avg_dtw_featavg)\n",
    "\n",
    "        my_model_avg_dtw_tbil_distances.append(avg_dtw_tbil_my)\n",
    "        base_model_avg_dtw_tbil_distances.append(avg_dtw_tbil_base)\n",
    "        random_model_avg_dtw_tbil_distances.append(avg_dtw_tbil_random)\n",
    "        featavg_model_avg_dtw_tbil_distances.append(avg_dtw_tbil_featavg)\n",
    "\n",
    "        my_model_avg_dtw_plt_distances.append(avg_dtw_plt_my)\n",
    "        base_model_avg_dtw_plt_distances.append(avg_dtw_plt_base)\n",
    "        random_model_avg_dtw_plt_distances.append(avg_dtw_plt_random)\n",
    "        featavg_model_avg_dtw_plt_distances.append(avg_dtw_plt_featavg)\n",
    "\n",
    "        my_model_avg_dtw_latic_distances.append(avg_dtw_latic_my)\n",
    "        base_model_avg_dtw_latic_distances.append(avg_dtw_latic_base)\n",
    "        random_model_avg_dtw_latic_distances.append(avg_dtw_latic_random)\n",
    "        featavg_model_avg_dtw_latic_distances.append(avg_dtw_latic_featavg)\n",
    "\n",
    "    # --- E. Extend Aggregate Lists (End of Fold Loop) ---\n",
    "    all_folds_my_dtw.extend(my_model_avg_dtw_distances)\n",
    "    all_folds_base_dtw.extend(base_model_avg_dtw_distances)\n",
    "    all_folds_random_dtw.extend(random_model_avg_dtw_distances)\n",
    "    all_folds_featavg_dtw.extend(featavg_model_avg_dtw_distances)\n",
    "\n",
    "    all_folds_my_tbil_dtw.extend(my_model_avg_dtw_tbil_distances)\n",
    "    all_folds_base_tbil_dtw.extend(base_model_avg_dtw_tbil_distances)\n",
    "    all_folds_random_tbil_dtw.extend(random_model_avg_dtw_tbil_distances)\n",
    "    all_folds_featavg_tbil_dtw.extend(featavg_model_avg_dtw_tbil_distances)\n",
    "\n",
    "    all_folds_my_plt_dtw.extend(my_model_avg_dtw_plt_distances)\n",
    "    all_folds_base_plt_dtw.extend(base_model_avg_dtw_plt_distances)\n",
    "    all_folds_random_plt_dtw.extend(random_model_avg_dtw_plt_distances)\n",
    "    all_folds_featavg_plt_dtw.extend(featavg_model_avg_dtw_plt_distances)\n",
    "    \n",
    "    all_folds_my_latic_dtw.extend(my_model_avg_dtw_latic_distances)\n",
    "    all_folds_base_latic_dtw.extend(base_model_avg_dtw_latic_distances)\n",
    "    all_folds_random_latic_dtw.extend(random_model_avg_dtw_latic_distances)\n",
    "    all_folds_featavg_latic_dtw.extend(featavg_model_avg_dtw_latic_distances)\n",
    "\n",
    "    print(\"Calculation finished.\")\n",
    "    print(\n",
    "        f\"Number of valid paired comparisons: {len(my_model_avg_dtw_distances)}\")\n",
    "\n",
    "# --- Step 3: Test for statistical significance ---\n",
    "# convert list to numpy\n",
    "all_folds_my_dtw = np.array(all_folds_my_dtw)\n",
    "all_folds_base_dtw = np.array(all_folds_base_dtw)\n",
    "all_folds_random_dtw = np.array(all_folds_random_dtw)\n",
    "all_folds_featavg_dtw = np.array(all_folds_featavg_dtw)\n",
    "\n",
    "all_folds_my_tbil_dtw = np.array(all_folds_my_tbil_dtw)\n",
    "all_folds_base_tbil_dtw = np.array(all_folds_base_tbil_dtw)\n",
    "all_folds_random_tbil_dtw = np.array(all_folds_random_tbil_dtw)\n",
    "all_folds_featavg_tbil_dtw = np.array(all_folds_featavg_tbil_dtw)\n",
    "\n",
    "all_folds_my_plt_dtw = np.array(all_folds_my_plt_dtw)\n",
    "all_folds_base_plt_dtw = np.array(all_folds_base_plt_dtw)\n",
    "all_folds_random_plt_dtw = np.array(all_folds_random_plt_dtw)\n",
    "all_folds_featavg_plt_dtw = np.array(all_folds_featavg_plt_dtw)\n",
    "\n",
    "all_folds_my_latic_dtw = np.array(all_folds_my_latic_dtw)\n",
    "all_folds_base_latic_dtw = np.array(all_folds_base_latic_dtw)\n",
    "all_folds_random_latic_dtw = np.array(all_folds_random_latic_dtw)\n",
    "all_folds_featavg_latic_dtw = np.array(all_folds_featavg_latic_dtw)\n",
    "\n",
    "results_summary = {\n",
    "    'Method': ['My Model', 'Base Model', 'Random', 'FeatureAvg'],\n",
    "    'Mean DTW': [np.nanmean(d) for d in [all_folds_my_dtw, all_folds_base_dtw, all_folds_random_dtw, all_folds_featavg_dtw]],\n",
    "    'Std Dev DTW': [np.nanstd(d) for d in [all_folds_my_dtw, all_folds_base_dtw, all_folds_random_dtw, all_folds_featavg_dtw]],\n",
    "    'Median DTW': [np.nanmedian(d) for d in [all_folds_my_dtw, all_folds_base_dtw, all_folds_random_dtw, all_folds_featavg_dtw]],\n",
    "    'IQR DTW': [scipy_iqr(d, nan_policy='omit') for d in [all_folds_my_dtw, all_folds_base_dtw, all_folds_random_dtw, all_folds_featavg_dtw]],\n",
    "    'N Valid': [np.sum(~np.isnan(d)) for d in [all_folds_my_dtw, all_folds_base_dtw, all_folds_random_dtw, all_folds_featavg_dtw]]\n",
    "}\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n--- Summary Statistics (eSOFA Score) ---\")\n",
    "print(results_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "results_summary_tbil = {\n",
    "    'Method': ['My Model', 'Base Model', 'Random', 'FeatureAvg'],\n",
    "    'Mean DTW': [np.nanmean(d) for d in [all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, all_folds_random_tbil_dtw, all_folds_featavg_tbil_dtw]],\n",
    "    'Std Dev DTW': [np.nanstd(d) for d in [all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, all_folds_random_tbil_dtw, all_folds_featavg_tbil_dtw]],\n",
    "    'Median DTW': [np.nanmedian(d) for d in [all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, all_folds_random_tbil_dtw, all_folds_featavg_tbil_dtw]],\n",
    "    'IQR DTW': [scipy_iqr(d, nan_policy='omit') for d in [all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, all_folds_random_tbil_dtw, all_folds_featavg_tbil_dtw]],\n",
    "    'N Valid': [np.sum(~np.isnan(d)) for d in [all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, all_folds_random_tbil_dtw, all_folds_featavg_tbil_dtw]]\n",
    "}\n",
    "results_df_tbil = pd.DataFrame(results_summary_tbil)\n",
    "print(\"\\n--- Summary Statistics (Total Bilirubin) ---\")\n",
    "print(results_df_tbil.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "results_summary_plt = {\n",
    "    'Method': ['My Model', 'Base Model', 'Random', 'FeatureAvg'],\n",
    "    'Mean DTW': [np.nanmean(d) for d in [all_folds_my_plt_dtw, all_folds_base_plt_dtw, all_folds_random_plt_dtw, all_folds_featavg_plt_dtw]],\n",
    "    'Std Dev DTW': [np.nanstd(d) for d in [all_folds_my_plt_dtw, all_folds_base_plt_dtw, all_folds_random_plt_dtw, all_folds_featavg_plt_dtw]],\n",
    "    'Median DTW': [np.nanmedian(d) for d in [all_folds_my_plt_dtw, all_folds_base_plt_dtw, all_folds_random_plt_dtw, all_folds_featavg_plt_dtw]],\n",
    "    'IQR DTW': [scipy_iqr(d, nan_policy='omit') for d in [all_folds_my_plt_dtw, all_folds_base_plt_dtw, all_folds_random_plt_dtw, all_folds_featavg_plt_dtw]],\n",
    "    'N Valid': [np.sum(~np.isnan(d)) for d in [all_folds_my_plt_dtw, all_folds_base_plt_dtw, all_folds_random_plt_dtw, all_folds_featavg_plt_dtw]]\n",
    "}\n",
    "results_df_plt = pd.DataFrame(results_summary_plt)\n",
    "print(\"\\n--- Summary Statistics (Platelet Count) ---\")\n",
    "print(results_df_plt.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "results_summary_latic = {\n",
    "    'Method': ['My Model', 'Base Model', 'Random', 'FeatureAvg'],\n",
    "    'Mean DTW': [np.nanmean(d) for d in [all_folds_my_latic_dtw, all_folds_base_latic_dtw, all_folds_random_latic_dtw, all_folds_featavg_latic_dtw]],\n",
    "    'Std Dev DTW': [np.nanstd(d) for d in [all_folds_my_latic_dtw, all_folds_base_latic_dtw, all_folds_random_latic_dtw, all_folds_featavg_latic_dtw]],\n",
    "    'Median DTW': [np.nanmedian(d) for d in [all_folds_my_latic_dtw, all_folds_base_latic_dtw, all_folds_random_latic_dtw, all_folds_featavg_latic_dtw]],\n",
    "    'IQR DTW': [scipy_iqr(d, nan_policy='omit') for d in [all_folds_my_latic_dtw, all_folds_base_latic_dtw, all_folds_random_latic_dtw, all_folds_featavg_latic_dtw]],\n",
    "    'N Valid': [np.sum(~np.isnan(d)) for d in [all_folds_my_latic_dtw, all_folds_base_latic_dtw, all_folds_random_latic_dtw, all_folds_featavg_latic_dtw]]\n",
    "}\n",
    "results_df_latic = pd.DataFrame(results_summary_latic)\n",
    "print(\"\\n--- Summary Statistics (Lactic Acid) ---\")\n",
    "print(results_df_latic.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "print(\"\\n--- Statistical Test (Wilcoxon Signed-Rank Test) ---\")\n",
    "alpha = 0.05\n",
    "\n",
    "# --- Function to perform and print Wilcoxon test ---\n",
    "def perform_wilcoxon(data1, data2, label1, label2, alternative='less'):\n",
    "    print(f\"\\nComparison: {label1} vs {label2}\")\n",
    "    # Pingouin handles NaNs by default using pairwise deletion\n",
    "    test_results = pg.wilcoxon(data1, data2, alternative=alternative)\n",
    "    p_val = test_results['p-val'].iloc[0]\n",
    "    rbc = test_results['RBC'].iloc[0] # Rank-Biserial Correlation\n",
    "    cles = test_results['CLES'].iloc[0] # Common Language Effect Size\n",
    "\n",
    "    print(f\"   Wilcoxon Test (H1: {label1} < {label2}):\")\n",
    "    print(f\"     P-value: {p_val:.4g}\") # Use general format for small p-values\n",
    "    print(f\"     Effect Size (Rank-Biserial Correlation, RBC): {rbc:.4f}\")\n",
    "    print(f\"     Effect Size (Common Language Effect Size, CLES): {cles:.4f}\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(f\"     Result: Statistically significant difference (p < {alpha}).\")\n",
    "    else:\n",
    "        print(f\"     Result: No statistically significant difference (p >= {alpha}).\")\n",
    "    return p_val, rbc, cles\n",
    "\n",
    "# Perform tests\n",
    "print(\"\\n--- Statistical Tests (eSOFA Score) ---\")\n",
    "p_my_base, rbc_my_base, cles_my_base = perform_wilcoxon(all_folds_my_dtw, all_folds_base_dtw, \"My Model\", \"Base Model\")\n",
    "p_my_random, rbc_my_random, cles_my_random = perform_wilcoxon(all_folds_my_dtw, all_folds_random_dtw, \"My Model\", \"Random\")\n",
    "p_my_featavg, rbc_my_featavg, cles_my_featavg = perform_wilcoxon(all_folds_my_dtw, all_folds_featavg_dtw, \"My Model\", \"FeatureAvg\")\n",
    "\n",
    "print(\"\\n--- Statistical Tests (Total Bilirubin) ---\")\n",
    "p_my_base, rbc_my_base, cles_my_base = perform_wilcoxon(all_folds_my_tbil_dtw, all_folds_base_tbil_dtw, \"My Model\", \"Base Model\")\n",
    "p_my_random, rbc_my_random, cles_my_random = perform_wilcoxon(all_folds_my_tbil_dtw, all_folds_random_tbil_dtw, \"My Model\", \"Random\")\n",
    "p_my_featavg, rbc_my_featavg, cles_my_featavg = perform_wilcoxon(all_folds_my_tbil_dtw, all_folds_featavg_tbil_dtw, \"My Model\", \"FeatureAvg\")\n",
    "\n",
    "print(\"\\n--- Statistical Tests (Platelet Count) ---\")\n",
    "p_my_base, rbc_my_base, cles_my_base = perform_wilcoxon(all_folds_my_plt_dtw, all_folds_base_plt_dtw, \"My Model\", \"Base Model\")\n",
    "p_my_random, rbc_my_random, cles_my_random = perform_wilcoxon(all_folds_my_plt_dtw, all_folds_random_plt_dtw, \"My Model\", \"Random\")\n",
    "p_my_featavg, rbc_my_featavg, cles_my_featavg = perform_wilcoxon(all_folds_my_plt_dtw, all_folds_featavg_plt_dtw, \"My Model\", \"FeatureAvg\")\n",
    "\n",
    "print(\"\\n--- Statistical Tests (Lactic Acid) ---\")\n",
    "p_my_base, rbc_my_base, cles_my_base = perform_wilcoxon(all_folds_my_latic_dtw, all_folds_base_latic_dtw, \"My Model\", \"Base Model\")\n",
    "p_my_random, rbc_my_random, cles_my_random = perform_wilcoxon(all_folds_my_latic_dtw, all_folds_random_latic_dtw, \"My Model\", \"Random\")\n",
    "p_my_featavg, rbc_my_featavg, cles_my_featavg = perform_wilcoxon(all_folds_my_latic_dtw, all_folds_featavg_latic_dtw, \"My Model\", \"FeatureAvg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16efdfd-ad90-4247-9833-bce85e305634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
